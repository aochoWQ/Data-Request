
#Creating a Shiny app by referencing Basin Criteria
#Load Basin Criteria
#Load all other criteria?
```{r}
sj_comb_crit=read.csv("/Users/alanochoa/Documents/GitHub/Data_Request/San Juan/SJ_combined_criteria.csv")

#Can the basin criteria be the min value for each grouping of  #Screening.Criteria, Use, Parameter, SampleType, Criteria_mg_L
#The calculated criteria may be an issue because the criteria is not straight forward and is based off of harness and different equations. May need to analyze these and check which is the most stringent formula for each parameter, however still not sure if that is fair because of the different hardness..

basin_crit=sj_comb_crit%>%
  filter(!Jurisdiction%in%c("EPA","Region 6","Region 9"))%>%
  group_by(Screening.Criteria, Use, Parameter, SampleType)%>%
  mutate(Crit_mg_l=min(Criteria_mg_L))%>%
  select(-Enter.Hardness..mg.L., -ln.Hardness,-ma.slope,-mb.intercept,-conversion.factor.alpha..ln.hardness..beta.,-alpha,-beta,-Solve.Ln,-Criteria_mg_L,-Jurisdiction)%>%
  distinct(.)%>%
  filter(!is.na(Crit_mg_l))

#Two options for the basin-wide criteria
#Option 1 work with the criteria that Kate Sullivan created - Does not include calculated criteria, she tended to choose stricter criteria often EPA recommendations. 
basin_crit_kate=read_csv("/Users/alanochoa/Documents/GitHub/Data_Request/San Juan/Master Animas-San Juan Comparative Standards Chart_For Wateshed Goals_FINAL 2021.xlsx - Combined One Basin.csv")

#Option 2 Consolidate the Beneficial Use names in the df created above basin_crit. Currently has 320 criteria ranging from 1 to 28 different criteria for various Parameters.There are 32 different Uses but many of these can be consolidated.



```


#Load various layers
#HUC12, Tribe boundaries, State boundaries
```{r}
huc12=wqTools::huc12_poly
#huc is large need to narrow down to only hucs in area
library(dplyr)
# Filter for only jurisdictions in : combined_all_criteria,"SJ_combined_criteria.csv")
jurisdictions=c("Colorado",  "Navajo Nation",  "New Mexico", "Utah", "Ute Mountain")

statesJSON <- st_read("./Spatial Layers/states.geojson") #selected_states
sj_states=statesJSON[statesJSON$NAME%in%jurisdictions,]

tribesJSON <- st_read("./Spatial Layers/tribes.geojson")
sj_tribes=tribesJSON[tribesJSON$NAME%in%jurisdictions,]

regionsJSON <- st_read("./Spatial Layers/EPA_regions.geojson")
unique_sj_sites=sj_sites%>%select( MonitoringLocationIdentifier,MonitoringLocationName,LatitudeMeasure,LongitudeMeasure)

library(sf)

```

#Load the data - Prepare data 
#Add Month & Year columns - Numeric to take up less space? 
#All criteria are mg/L - Convert to correct unit.
#Test how to apply calculated Criteria
#Annotate NonDetects
#Criteria Attached for each different crit?

```{r}
### results_Animas_SJ2 FROM SJ_data_download.Rmd line 58
#filter for only Parameters of Interest
crit_params=c(unique(sj_comb_crit$Parameter),"Total hardness") #"Hardness, carbonate"
sj_all_params=unique(results_Animas_SJ2$CharacteristicName)
prepped_sj_data=results_Animas_SJ2[results_Animas_SJ2$CharacteristicName%in%crit_params,]%>%
  mutate(Month = format(as.Date(ActivityStartDate, format = "%Y-%m-%d"), "%m"),  
    Year = format(as.Date(ActivityStartDate, format = "%Y-%m-%d"), "%Y"))%>%
  select(where(~!all(is.na(.))))%>% #Clean up columns where all values are NA
  filter(!ResultWeightBasisText=="Dry")

prepped_sj_data_counts=prepped_sj_data%>%
  group_by(ResultIdentifier)%>%
  mutate(count=n())%>%filter(count>1)%>%arrange(ResultIdentifier)

sj_na_vals=prepped_sj_data[!prepped_sj_data$ResultDetectionConditionText=="",]
sj_detect_vals=prepped_sj_data[prepped_sj_data$ResultDetectionConditionText=="",]



##CHUNK OF CODE FOR Calculated Criteria
if (screen$alphaBeta[b] == 0) { #calculator function 1 y=1
for (y in 1:nrow(tempSamples)) { #iterate through each sample 
screen$value[b] <- as.numeric((exp((screen$maSlope[b]*log(tempSamples$Hardness[y]))+screen$mbIntercept[b])*screen$conversionFactor[b])/1) #calculate criteria
if (input$Categories==TRUE)  {

for (x in 1:length(GroupCategories[-c(1,length(GroupCategories))])) { # gets 
    aquatic_screenvars2[x] <- if (length(GroupCategories[-length(GroupCategories)])>1) {nCategories[i,x]} else {nCategories[i]}
}
aquatic_screenvars3 <- c(screen$Sample_Type[b], # Sample_Type
                         screen$ScreenType[b], # ScreenType
                         tempSamples$Lat[y], # Lat
                         tempSamples$Lon[y], # Lon
                         screen$variable[b], # CritMetal
                         as.numeric(screen$value[b]), # Criteria
                         as.numeric(tempSamples$conc[y]), # SampleValue
                         tempSamples$variable[y]) # ObsMetal

aquatic_screenvarTot <- c(aquatic_screenvars1,aquatic_screenvars2,aquatic_screenvars3)
aquatic_screen[g,] <- aquatic_screenvarTot
aquatic_screen[, c("Criteria", "SampleValue", "Lat", "Lon")] <- sapply(aquatic_screen[, c("Criteria", "SampleValue", "Lat", "Lon")], as.numeric)
g=g+1
}

aquatic_screen[, c("Criteria", "SampleValue", "Lat", "Lon")] <- sapply(aquatic_screen[, c("Criteria", "SampleValue", "Lat", "Lon")], as.numeric)
g=g+1
}
}
  
  ####CALCULATED #2
} else if (screen$alphaBeta[b] == 1) { #calculator function 2 
for (z in 1:nrow(tempSamples)) { #iterate through each sample
screen$value[b] <- as.numeric((exp((screen$maSlope[b]*log(tempSamples$Hardness[z])+screen$mbIntercept[b]))*(screen$alpha[b]-(log(tempSamples$Hardness[z])*screen$beta[b])))/1) #calculate criteria


  
                      

```


#Draft App
```{r}

#Load data files: HUC12s, Sample_Data, Criteria df

library(shiny)
library(leaflet)
library(sf)
library(dplyr)

sj_data = results_Animas_SJ #******CHANGE THIS TO CORRECT DATA


#******Decide if we will need to consolidate Param names. If so create new columns.. Shiny currently references ResultSampleFractionText and CharacteristicName

# UI
ui = fluidPage(
  titlePanel("San Juan Water Quality Dashboard"),
  sidebarLayout(
    sidebarPanel(
      selectInput("parameter", "Select Parameter:", choices = unique(sj_data$CharacteristicName)),
      selectInput("fraction", "Select Fraction:", choices = c("Total", "Dissolved")),
      selectInput("summaryType", "Value Summary Type:", choices = c("Average", "Weighted Average", "Normalized Average", "Median", "Percentile")),
      actionButton("update", "Update Map")
    ),
    mainPanel(
      leafletOutput("choroplethMap"),
      plotOutput("dataDist")
    )
  )
)

# Server
server <- function(input, output) {
  observeEvent(input$update, {
    # Data preparation based on selections
    data_filtered <- data %>%
      filter(CharacteristicName == input$parameter, ResultSampleFractionText == input$fraction) %>% 
      group_by(HUC_12) %>% ##****** Need to add HUC12 data to this.. also decide if this is the best way to group the data together
      summarize(Value = case_when(
        input$summaryType == "Average" ~ mean(Value, na.rm = TRUE),
        input$summaryType == "Weighted Average" ~ sum(Value * SampleSize) / sum(SampleSize),
        input$summaryType == "Normalized Average" ~ mean(Value / NormalizingFactor, na.rm = TRUE),
        input$summaryType == "Median" ~ median(Value, na.rm = TRUE),
        input$summaryType == "Percentile" ~ quantile(Value, 0.9, na.rm = TRUE)
      ))
    
    # Update map
    output$choroplethMap <- renderLeaflet({
      leaflet(data_filtered) %>%
        addTiles() %>%
        addPolygons(fillColor = ~colorQuantile("YlOrRd", Value, n = 5)(Value),
                    fillOpacity ="blue")
    })
    
    
  })
  
  #Should this be outside of the previous code or put it inside its own observe event??
  output$dataDist <- renderPlot({
    data <- reactive_data()
    hist(data$Value, breaks = 30, main = paste("Distribution of", input$parameter," by site."))#Can you change it so it is by site? or different chart??
    
  })
}

# Run the app
shinyApp(ui, server)

```